{"./":{"url":"./","title":"Introduction","keywords":"","body":"SOP https://github.com/tzq0301/sop GitBook 教程 "},"docs/ansible.html":{"url":"docs/ansible.html","title":"Ansible","keywords":"","body":"Ansible Install Installing Ansible python3 -m pip -V # 查看 pip 是否可用（使用 pip 安装 Ansible） python3 -m pip install --user ansible # 安装 Ansible（若出问题，可参考 Python 配置国内镜像源） # 安装完可能会有黄色的 WARNING，提示 /home/用户名/.local/bin 不在 PATH 中 # 此时，我们需要进行一下配置，否则无法直接使用 ansible echo \"export PATH=/home/$(whoami)/.local/bin:\\$PATH\" >> ~/.bashrc && echo source ~/.bashrc && echo \"OK\" ansible --version ansible-playbook --version Ansible Ad-hoc Commands ansible pattern -m [module] -a \"[module options]\" # /etc/ansible/hosts 默认的 inventory 文件 # /etc/ansible/ansible.cfg 默认的配置文件 # ~/.ansible.cfg 如果存在，就 override 默认的配置文件 兼容 CPU 架构 - name: this is x86_64 debug: msg: \"Hello {{ ansible_architecture }}\" when: ansible_architecture == 'x86_64' - name: this is aarch64 debug: msg: \"Hello {{ ansible_architecture }}\" when: ansible_architecture == 'aarch64' "},"docs/cpp.html":{"url":"docs/cpp.html","title":"C++","keywords":"","body":"C++ 示例：CMake 使用 FetchContent cmake_minimum_required(VERSION 3.26) project(Learning_CMake) set(CMAKE_CXX_STANDARD 23) include(FetchContent) FetchContent_Declare(fmt GIT_REPOSITORY https://github.com/fmtlib/fmt.git) FetchContent_MakeAvailable(fmt) FetchContent_Declare(Boost # GIT_REPOSITORY https://github.com/boostorg/boost.git URL https://github.com/boostorg/boost/releases/download/boost-1.83.0/boost-1.83.0.tar.xz DOWNLOAD_EXTRACT_TIMESTAMP ON) FetchContent_MakeAvailable(Boost) add_executable(Learning_CMake main.cpp) target_link_libraries(Learning_CMake PRIVATE fmt Boost::uuid Boost::lexical_cast) "},"docs/docker.html":{"url":"docs/docker.html","title":"Docker","keywords":"","body":"Docker build & run docker run --rm $(docker build . -q) 使用 non-root user 管理 Docker The docker group grants root-level privileges to the user. For details on how this impacts security in your system, see Docker Daemon Attack Surface. sudo groupadd docker sudo usermod -aG docker $USER newgrp docker # or logout and log back to make sure that your group membership is re-evaluated Docker 导出/加载镜像 docker save -o helloworld.tar nju/hello-world:1.0.0 docker load -i helloworld.tar docker export busybox > busybox.tar docker import busybox.tar busybox:test buildx 构建多架构镜像 docker buildx build \\ --platform linux/amd64,linux/arm64 \\ # 参考 https://github.com/docker-library/official-images#architectures-other-than-amd64 -t YOUR_IMAGENAME:YOUT_IMAGE_TAG \\ --push \\ # 构建完就 push（如果只想 build、不想 push，就去掉 --push） . # Dockerfile 所在的文件夹 删除空悬镜像 docker image prune 分析镜像 dive dive alpine vs distroless Alpine 镜像的优点在于它的体积小且包含了一个全功能的包管理器：这意味着你可以轻易地在镜像中安装额外的软件包；但同时，这样可能会导致更大的攻击面，因为镜像中可能会包含一些并不需要的软件包 此外，Alpine 使用的是 musl libc 和 busybox，这可能会与一些 glibc 的应用产生不兼容问题 Distroless 镜像的设计理念是“尽可能只包含应用运行所需的最小系统文件和依赖项”，这可以降低镜像的攻击面，提高应用的安全性 Distroless 不包含任何包管理工具或 shell，这意味着无法在运行时安装额外的软件包或在终端中运行命令，这对于需要提高容器安全性的应用来说是一个重大的优点 busybox - Linux 瑞士军刀 集成了数百个 Linux 命令（例如 curl、grep、mount、telnet 等）的精简工具箱，只有几兆大小，可以用来做调试来查找生产环境中遇到的问题 docker pull busybox 快速启动 MySQL 实例 docker run -p 3306:3306 --name mysql -e MYSQL_ALLOW_EMPTY_PASSWORD=yes -d mysql 示例：Dockerfile - Go 语言 # syntax=docker/dockerfile:1 # Build the application from source FROM golang:1.22 AS build-stage WORKDIR /app COPY go.mod go.sum ./ RUN go mod download COPY *.go ./ RUN CGO_ENABLED=0 GOOS=linux go build -o /main # Run the tests in the container FROM build-stage AS run-test-stage RUN go test -v ./... # Deploy the application binary into a lean image FROM gcr.io/distroless/base-debian11 AS build-release-stage WORKDIR / COPY --from=build-stage /main /main # Optional: # To bind to a TCP port, runtime parameters must be supplied to the docker command. # But we can document in the Dockerfile what ports # the application is going to listen on by default. # https://docs.docker.com/reference/dockerfile/#expose EXPOSE 8080 USER nonroot:nonroot ENTRYPOINT [\"/main\"] 配置镜像源 若无 /etc/docker/daemon.json 文件，则执行以下命令（若存在该命令，则照猫画虎，修改对应 json 属性即可）： sudo tee /etc/docker/daemon.json 重新启动服务即可： sudo systemctl daemon-reload sudo systemctl restart docker "},"docs/git.html":{"url":"docs/git.html","title":"Git","keywords":"","body":"Git git config git config --global core.editor \"vim\" git config --global user.name \"John Doe\" git config --global user.email \"johndoe@example.com\" 检查配置： git config --list git commit git commit --amend --no-edit # --amend 不修改 commit message git log git log --online # 一行显示一个 commit 信息 git rev-parse git rev-parse HEAD # commit id git rev-parse --short HEAD # shorter commit id git rev-parse --abbrev-ref HEAD # 当前 branch git rev-parse --show-toplevel # 当前 git 根目录 示例：.gitignore .idea/ .fleat/ .vscode/ .settings/ .DS_Store .AppleDouble .LSOverride Icon .Spotlight-V100 .Trashes Thumbs.db ehthumbs.db Desktop.ini *.log *.sqlite *.db *.war *.jar *.class *.exe *.exe~ *.out *.o *.so *.ddl *.dylib *.7z *.dmg *.gz *.iso *.jar *.rar *.tar *.zip target/ out/ build/ go.work *.test *.prof vendor/ *.out 添加后，gitignore 可能不会生效，此时运行以下命令： git rm -rf --cached . git add . "},"docs/go-lib.html":{"url":"docs/go-lib.html","title":"Go Library","keywords":"","body":"Go Library uber-go/automaxprocs 在 Docker Container 容器中，runtime.GOMAXPROCS() 获取的是宿主机的 CPU 核数，那么当使用 cgroups 对容器的 CPU 进行限制、但 Go 程序仍使用宿主机核数时，就会造成【 P 值设置过大，导致生成线程过多，会增加上线文切换的负担，造成严重的上下文切换，浪费 CPU 】的问题 因此，需要使用 uber-go/automaxprocs 来读取 CGroup 值，以识别容器的 CPU quota，计算得到实际核心数，并自动设置 GOMAXPROCS 线程数量 package main import ( \"runtime\" \"go.uber.org/automaxprocs/maxprocs\" ) // docker run --rm $(docker build . -q) // docker run --rm --cpus=\"2\" $(docker build . -q) func main() { maxprocs.Set() // 安全加强库 google/safetext 防止 yaml 注入和 shell 注入，用于替代 text/template google/safeopen 防止路径遍历攻击（例如：指定一个受信任的根目录后，文件操作不能超过该目录） google/safearchive 防止路径遍历攻击和处理归档文件相关的攻击（例如 ./././././etc/cron.daily/cronjob），支持跳过特殊文件、净化文件名、防止通过符号链接进行遍历等 "},"docs/javascript.html":{"url":"docs/javascript.html","title":"JavaScript","keywords":"","body":"JavaScript 破解网页不可粘贴内容等限制 var allowPaste = function(e){ e.stopImmediatePropagation(); return true; }; document.addEventListener('paste', allowPaste, true); "},"docs/kubernetes.html":{"url":"docs/kubernetes.html","title":"Kubernetes","keywords":"","body":"Kubernetes alias k='kubectl' # po pods # no nodes # deploy deployments # svc services # rs replicasets # ns namespace # cm configmap # get 列出资源 kubectl get pods kubectl get nodes kubectl get deployments kubectl get services kubectl get replicasets kubectl get services $SERVICE_NAME kubectl get deployments $DEPLOYMENT_NAME kubectl get pods -o wide # 更多的列（更详细的信息） # describe 显示有关资源的详细信息 # describe 的输出设计为人类可读的信息，而不是脚本化的信息 kubectl describe pods kubectl describe nodes kubectl describe deployments # logs 打印 Pod 中容器的日志 kubectl logs $POD_NAME # exec 在 Pod 中的容器上执行命令 kubectl exec $POD_NAME -- env # 列出 Pod 的容器中的环境变量 kubectl exec -it $POD_NAME -- bash # 在 Pod 的容器中启动一个 bash 会话 # Pod 运行在隔离的、私有的网络中，因此我们需要 proxy 访问它们，这样才能进行调试和交互 kubectl proxy kubectl label pods $POD_NAME $LABEL=$LABEL_VALUE kubectl get pods -l $LABEL=$LABEL_VALUE kubectl get services -l $LABEL=$LABEL_VALUE kubectl delete service -l $LABEL=$LABEL_VALUE # 扩缩容 kubectl scale deployments/$DEPLOYMENT_NAME --replicas=$NUM # 更新应用程序的镜像版本，并启动滚动更新 kubectl set image deployments/$DEPLOYMENT_NAME $DEPLOYMENT_NAME=$NEW_IMAGE # 通过运行 rollout status 来确认此次更新 kubectl rollout status deployments/$DEPLOYMENT_NAME # 回滚 Deployment 到上一个工作的版本 kubectl rollout undo deployments/$DEPLOYMENT_NAME "},"docs/mysql/mysql.html":{"url":"docs/mysql/mysql.html","title":"MySQL","keywords":"","body":"MySQL "},"docs/mysql/mysql-commands.html":{"url":"docs/mysql/mysql-commands.html","title":"MySQL 命令","keywords":"","body":"MySQL 命令行 cli 连接 MySQL Server # 在命令行里写明文密码是不安全的，例如 mysql -h$Host -u$Username -p$Password 会报 [Warning] Using a password on the command line interface can be insecure. # # 安全的方法（选其一即可）： # * 使用 mysql_config_editor 将身份凭证存储在 .mylogin.cnf 加密登录路径文件中，参考 https://dev.mysql.com/doc/refman/8.0/en/mysql-config-editor.html # * 在命令行里使用 -p 或 --password 选项，让客户端程序提示输入密码 # * 在 ~/.my.cnf 文件中配置明文密码，详细参考 https://dev.mysql.com/doc/refman/8.0/en/password-security-user.html#:~:text=%5Bclient%5D%0Apassword%3Dpassword # MYSQL_PWD=$Password mysql -h$Host -u$Username # 正确的方式是将 MYSQL_PWD 环境变量在其他地方进行设置 命令行 cli 执行 MySQL 命令（不进入交互模式） mysql -e \"SELECT VERSION();\" 查看某库中某表的自增 ID 计数器 SELECT `AUTO_INCREMENT` FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_SCHEMA = 'YOUR_DATABASE' AND TABLE_NAME = 'YOUR_TABLE'; -- WHERE TABLE_SCHEMA = DATABASE() AND TABLE_NAME = 'YOUR_TABLE'; 根据旧表建新表 CREATE TABLE new_table LIKE old_table; -- LIKE 会包含列信息和索引信息 -- CREATE TABLE new_table -- SELECT * -- SELECT 只会复制列信息，不会复制索引信息 -- FROM old_table; 查看 server id SELECT @@server_id; 查看当前的 connections 连接数 mysql -e \"SHOW PROCESSLIST;\" | tail -n +2 | wc -l 最大连接数 SELECT @@GLOBAL.max_connections; -- 服务器上同时存在的最大连接数 SELECT @@GLOBAL.max_user_connections; -- 单个用户可以同时建立的连接数 慢查询日志 SELECT @@GLOBAL.slow_query_log; -- 启用或禁用慢查询日志功能（有效值：ON/1、OFF/0） SELECT @@GLOBAL.slow_query_log_file; -- 慢查询日志文件存储位置 SELECT @@GLOBAL.long_query_time; -- 设置慢查询的阈值时间（单位：秒） SELECT @@GLOBAL.log_queries_not_using_indexes; -- 是否记录那些未使用索引的查询语句到慢查询日志中（有效值：ON/1、OFF/0） 若开启了慢查询日志，需要注意慢查询日志文件的定期备份与清理，避免浪费磁盘空间 cat /dev/null > $SLOW_QUERY_LOG_FILE 查看 innodb_buffer_pool_size 内存大小 SELECT @@innodb_buffer_pool_size/1024/1024/1024; -- 以 G 为单位 查看实例当前拥有的 binlog SHOW BINARY LOGS; 在线查看 binlog 内容 SHOW BINLOG EVENTS [IN 'log_name'] [FROM pos] [LIMIT [offset,], row_count]; 时间类型与 INT、VARCHAR 等类型相互转换 -- NOW() -> VARCHAR SELECT DATE_FORMAT(NOW(6), '%Y-%m-%d %H:%m:%s.%f'); -- CURRENT_TIMESTAMP -> VARCHAR SELECT DATE_FORMAT(CURRENT_TIMESTAMP, '%Y-%m-%d %H:%m:%s.%f'); -- VARCHAR -> DATETIME -- %W: Weekday name from Sunday to Saturday. -- %d: Day of the month as a numeric value from 01 to 31. -- %m: Month as a numeric value from 01 to 12. -- %Y: Year as a 4-digit numeric value (yyyy). -- %T: Time in the 24-hour format (hh:mm:ss). SELECT STR_TO_DATE('2023-07-13 03:49:11', '%Y-%m-%d %T'); -- BIGINT -> DATETIME SELECT FROM_UNIXTIME(1680873114); -- 毫秒 SELECT FROM_UNIXTIME(1680873114000 / 1000); -- 微秒 "},"docs/mysql/mysql-cluster.html":{"url":"docs/mysql/mysql-cluster.html","title":"MySQL Cluster","keywords":"","body":"MySQL Cluster 搭建主从连接 IP server-id 主库 source 192.168.244.10 1 从库 replica 192.168.244.20 2 在 source 端（主库），创建复制用户： mysql> CREATE USER 'repl'@'192.168.244.20' IDENTIFIED BY 'repl123'; Query OK, 0 rows affected (0.01 sec) mysql> GRANT REPLICATION SLAVE ON *.* TO 'repl'@'192.168.244.20'; Query OK, 0 rows affected (0.01 sec) 在 replica 端（从库），测试是否能连接到主库： mysql -h 192.168.244.10 -urepl -prepl123 在 replica 端（从库），执行 CHANGE MASTER TO 命令： 在主库中执行 SHOW MASTER STATUS 或 SHOW BINARY LOG STATUS，结果中的 File 与 Position 的值，就是 master_log_file 与 master_log_pos 的值 CHANGE MASTER TO master_host='192.168.244.10', master_user='repl', master_password='repl123', master_log_file='binlog.000002', master_log_pos=1988; 在 replica 端（从库），执行 START SLAVE 或 START REPLICA 命令，开启主从复制，并使用 SHOW SLAVE STATUS\\G 或 SHOW REPLICA STATUS\\G 进行检查：若 Slave_IO_Running 与 Slave_SQL_Running 的值均为 Yes，或 Replica_IO_Running 与 Replica_SQL_Running 的值均为 Yes，那么说明主从复制搭建成功 （可选）最后，在 source 随意执行一些 SQL，然后到 replica 查看数据是否已复制过来了 从库开启主从复制 START SLAVE; -- or START REPLICA; 从库停止主从复制 会同时停止 IO Thread 和 SQL Thread STOP SLAVE; -- or STOP REPLICA; 在主库查看从库 IP 和端口 SHOW SLAVE HOSTS; -- or SHOW REPLICAS; "},"docs/nginx.html":{"url":"docs/nginx.html","title":"Nginx","keywords":"","body":"Nginx 校验 Nginx 配置文件正确性 nginx -t 重新加载 Nginx 配置文件 nginx -s reload 示例：配置文件 nginx.conf # 帮助限制 Nginx 进程的权限，从而减少系统遭受恶意攻击的风险 # 通常，出于安全考虑，推荐不使用 root 用户运行网络服务 # user [groupname]; # 设置 Nginx 将启动的工作进程数目（默认为 1） # worker_processes 7; # 可以填数字 # worker_processes auto; # auto 代表设置为 CPU 核数 events { # 根据系统的文件描述符限制来配置 # 每个工作进程的最大连接数不应超过系统允许单个进程打开的文件描述符数量，可以通过 ulimit -n 命令查看或设置这个限制 # worker_connections 1024; } http { # include /etc/nginx/mime.types; # 能根据文件的扩展名来设置 HTTP 的 Content-Type # 引入所有 .conf 文件 # .conf 文件包含 server 块，可以用于文件的分离 # include /etc/nginx/conf.d/*.conf; # upstream 用于配制服务器集群 # backend-servers 可以替换为别的名字，该配置将在 server 块的 proxy_pass 中被使用 upstream backend-servers { # ip-hash server localhost:3000; server localhost:3001; # 可以为不同性能的服务器设置不同的权重 # server localhost:3000 weight=3; # server localhost:3001 weight=7; } server { listen 80; server_name localhost; # 静态文件的根目录 # root /var/www/localhost; # 设置默认的 index 页 # index index.html; # 配置 HTTPS 的默认访问端口为 443 # 如果未在此处配置HTTPS的默认访问端口，可能会造成 Nginx 无法启动 # listen 443 ssl; # ssl_certificate cert/cert-file-name.pem; # 修改为自己的 pem 的路径 # ssl_certificate_key cert/cert-file-name.key; # 修改为自己的 key 的路径 # ssl_session_timeout 5m; # ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; # 表示使用的加密套件的类型 # ssl_protocols TLSv1.1 TLSv1.2 TLSv1.3; # 表示使用的TLS协议的类型，您需要自行评估是否配置 TLSv1.1 协议 # ssl_prefer_server_ciphers on; location / { proxy_pass http://backend-servers; # backend-servers 为上面配置的一个 upstream 服务器集群的名字 } # DNS 解析 # resolver 8.8.8.8; # Google 公司的 DNS # resolver 114.114.114.114; # 中国移动用的 DNS } } 示例：docker-compose.yaml version: \"3\" services: gateway: image: nginx:latest entrypoint: - sh - -euc - | cat /etc/nginx/nginx.conf user nginx; worker_processes 5; ## Default: 1 events { worker_connections 1000; } http { resolver 127.0.0.11; server { listen 3100; location = / { return 200 'OK'; auth_basic off; } location = /api/prom/push { proxy_pass http://write:3100\\$$request_uri; } location = /api/prom/tail { proxy_pass http://read:3100\\$$request_uri; proxy_set_header Upgrade \\$$http_upgrade; proxy_set_header Connection \"upgrade\"; } location ~ /api/prom/.* { proxy_pass http://read:3100\\$$request_uri; } location = /loki/api/v1/push { proxy_pass http://write:3100\\$$request_uri; } location = /loki/api/v1/tail { proxy_pass http://read:3100\\$$request_uri; proxy_set_header Upgrade \\$$http_upgrade; proxy_set_header Connection \"upgrade\"; } location ~ /loki/api/.* { proxy_pass http://read:3100\\$$request_uri; } } } EOF /docker-entrypoint.sh nginx -g \"daemon off;\" ports: - \"3100:3100\" healthcheck: test: [\"CMD\", \"service\", \"nginx\", \"status\"] interval: 10s timeout: 5s retries: 5 "},"docs/python.html":{"url":"docs/python.html","title":"Python","keywords":"","body":"Python 安装 Python 3，并配置为默认 Python Interpreter 自动版：sudo apt update && sudo apt upgrade python3 安装编译 Python 源码所需要的组件 apt-get install wget build-essential libreadline-gplv2-dev libncursesw5-dev libssl-dev libsqlite3-dev tk-dev libgdbm-dev libc6-dev libbz2-dev libffi-dev zlib1g-dev liblzma-dev -y 在 Python 官方下载页面 中，找一个 Gzipped source tarball 的 Python 发行版，并“复制链接地址”（或者在 华为云镜像站 找一个），进行下载 # 下载 Python 源码（找 .tgz 后缀的） URL=你的链接 # URL=https://mirrors.huaweicloud.com/python/3.12.3/Python-3.12.3.tgz wget $URL # 解压下载的压缩包 tar zxvf $(basename \"$URL\") # 进入目录 cd $(basename \"$URL\" .tgz) # 编译源码，并进行安装 ./configure --enable-optimizations sudo make altinstall # 默认安装在 /usr/bin；如果不想覆盖默认的 Python，可以使用 altinstall 将 Python 安装在 /usr/local/bin 查看 /usr/local/bin 目录下的 Python 解释器，选择一个，将其设置为默认的 Python 解释器 ls /usr/local/bin/python* # 查看可选的 Python 解释器 PY= # 从上一步显示的若干个 Python 解释器中，选择一个，设置为 PY 临时环境变量，例如 PY=/usr/local/bin/python3.12 sudo update-alternatives --install /usr/bin/python python $PY 1 # 设置为默认的 Python 解释器 sudo update-alternatives --install /usr/bin/python3 python3 $PY 1 # 设置为默认的 Python 3 解释器 # 校验是否配置成功 python -V python3 -V python3 -m pip -V # pip3 -V pip 配置国内镜像源 mkdir ~/.pip cat ~/.pip/pip.conf [global] index-url = https://pypi.tuna.tsinghua.edu.cn/simple [install] trusted-host = https://pypi.tuna.tsinghua.edu.cn EOF pip3 config list # 查看镜像地址，验证是否已经成功修改镜像 镜像站 链接 华为镜像源 https://mirrors.huaweicloud.com/ 阿里云 http://mirrors.aliyun.com/pypi/simple/ 中国科学技术大学 http://pypi.mirrors.ustc.edu.cn/simple/ 清华大学 https://pypi.tuna.tsinghua.edu.cn/simple/ 浙江大学开源镜像站 http://mirrors.zju.edu.cn/ 腾讯开源镜像站 http://mirrors.cloud.tencent.com/pypi/simple 豆瓣 http://pypi.douban.com/simple/ 网易开源镜像站 http://mirrors.163.com/ 搜狐开源镜像 http://mirrors.sohu.com/ "},"docs/redis.html":{"url":"docs/redis.html","title":"Redis","keywords":"","body":"Redis "},"docs/shell/shell.html":{"url":"docs/shell/shell.html","title":"Shell","keywords":"","body":"Shell Bash 脚本教程 - WangDoc "},"docs/shell/shell-commands.html":{"url":"docs/shell/shell-commands.html","title":"Shell 命令","keywords":"","body":"Shell 命令 ls -l 使用 long listing format -t 根据时间排序 -S 根据文件大小排序 -r 在排序时反转顺序 -h 提高可读性 human readable ~ ls -lSh # 根据文件大小排序 total 81M total 52K -rw-rw-rw- 1 codespace codespace 4.8K Apr 20 14:21 shell.md -rw-rw-rw- 1 codespace codespace 4.4K Apr 18 03:26 nginx.md -rw-rw-rw- 1 codespace codespace 4.0K Apr 19 06:53 mysql.md -rw-rw-rw- 1 codespace codespace 2.2K Apr 20 09:40 ssh.md -rw-rw-rw- 1 codespace codespace 2.0K Apr 18 05:10 docker.md -rw-rw-rw- 1 codespace codespace 1.3K Apr 20 10:47 regexp.md -rw-rw-rw- 1 codespace codespace 862 Apr 18 04:51 git.md -rw-rw-rw- 1 codespace codespace 772 Apr 18 05:26 earlyoom.md -rw-rw-rw- 1 codespace codespace 661 Apr 18 04:23 cpp.md -rw-rw-rw- 1 codespace codespace 201 Apr 18 05:00 javascript.md -rw-rw-rw- 1 codespace codespace 166 Apr 18 02:56 vim.md grep # 正则匹配 grep -e pattern grep -E pattern # -E 表示“扩展正则” grep -P pattern # -P 表示“Perl 正则” grep -E 'a|w' # OR 或匹配 # “排除”匹配模式 grep -v '#' # 去掉包含 # 的行（可以用于过滤“注释行”等） # 查看指定内容上下几行 grep -10 '123' app.log # 前后 10 行 grep -C 10 '123' app.log # 前后 10 行 grep -A 10 -B 10 '123' app.log # 前后 10 行 grep -A 10 '123' app.log # 后 10 行（After） grep -B 10 '123' app.log # 前 10 行（Before） # 显示行号 grep -n sed 获取指定行 # -n 静默模式，防止输出文件全部内容 sed -n '3p' # 获取第 3 行 sed -n '2p;5p' # 获取第 2 行和第 5 行 sed -n '2,5p' # 获取第 2 ~ 5 行 sed -n '2,$p' # 获取第 2 ~ 最后一行 sed -n '1~3p' # 从第 1 行开始获取，step 为 3 # seq 20 | sed -n '1~3p' | tr '\\n' ' ' 的输出结果是 1 4 7 10 13 16 19 sed -n '/pattern/p' # 获取与 pattern 相匹配的所有行 sed -n '/2017/,/2024/p' # 范围获取“最先的包含字符串 2017 的行”到“最后的包含字符串 2024 的行” sed 替换内容 # s -> substitute # g -> global sed 's/C++/CPP/g' # 将 C++ 替换为 CPP 后的内容输出到标准输出 sed 's#C++#CPP#g' sed 's@C++@CPP@g' sed 's|C++|CPP|g' sed -i 's/C++/CPP/g' # 原地更新，将文件中的 C++ 替换为 CPP，-i --in-place # 给文件的每一行加上一个井号 sed 's/^/#/' 文件名 > 新文件名 sed -i 's/^/#/' 文件名 # 原地修改 sed -i.bak 's/C++/CPP/g' $FILENAME # 将文件 $FILENAME 拷贝一份为 $FILENAME.bak，再对文件 $FILENAME 进行原地更新 sed “扩展正则”匹配 sed -r pattern awk # awk 选项 '条件1 {动作1} 条件2 {动作2} 条件3 {动作3} ...' # # 内置变量： # * FILENAME 文件名 # * FNR 该行在某个文件中的行号 # * NR (Number of Record) 该行在 awk 输出的所有行中的行号 # * NF（Number of Field）每行有多少列，因此 $NF 可以表示最后一列 # * $0 表示“整行” # * FS（Field Splitter）列分隔符（可以在 BEGIN 时进行修改） # * RS（Row Splitter）行分隔符（可以在 BEGIN 时进行修改） awk 'NR==1' # 取第一行 awk 'NR==1{print $0}' # 取第一行 awk 'NR >= 2 && NR column 对齐每一列 column -t # 制表 column -t -s ',' # 指定分隔符来制表 tr tr ' ' '\\n' # 替换 space 为换行符 tee 在终端输出时，同时输出到文件 ls -a | tee output tail tail -n +2 \"$FILE\" # 去掉第一行 tail -10 \"$FILE\" # 文件最后 10 行 tail -n 10 \"$FILE\" # 文件最后 10 行 wc wc -l # 统计行数 mkdir # -p 父目录不存在就自动创建 mkdir -p # 在某个目录下，创建多个子目录 mkdir -p t/{a,b,c} tar # x -> 解压 # v -> verbose 输出日志 # f -> 指定文件 # -C -> 解压到目标文件夹，并 cd 到目标文件夹 tar xvf /mnt/gentoo/portage-latest.tar.gz -C /mnt/gentoo/usr # z -> 使用 gzip 进行压缩（不加 -z 即为“仅归档、不压缩”） tar zcf $Folder.tar.gz $Folder/ # .tar.gz 是经过 gzip 命令压缩过的 .tar 文件 tar cf $Folder.tar $Folder/ # .tar 文件：tar 是 Tape Archive 的缩写，表示归档 basename & dirname basename a/b/ccc.gz # ccc.gz basename a/b/ccc.gz .gz # ccc basename -s .gz a/b/ccc.gz # ccc dirname a/b/ccc.gz # a/b 展示当前时间 date '+%Y-%m-%d %H:%M:%S' # 2024-04-28 08:04:14 date '+%Y%m%d%H%M%S' # 20240428080414 查看文件大小 ls -lSh du -h | sort -hr 强制 apt install 不下载其“推荐”的软件包，以减少软件包的下载与安装 sudo apt install --no-install-recommends ... 输入输出重定向 Shell 中，总有三个文件处于打开状态 —— 标准输入（键盘输入）、标准输出（输出到屏幕）、标准错误（输出到屏幕），分别对应的文件描述符（file description）为 0、1、2 > 等价于 1>，即为“标准输出”重定向 2>&1 把“标准错误”重定向到“标准输出” &> file 将“标准输出”和“标准错误”都重定向到文件 file 中 /dev/null 是一个特殊文件，所有重定向到该文件的内容都会被丢弃掉，即当不想看到“输出”时可以使用 > /dev/null 或 &> /dev/null 清空一个文件的内容 :> $FILE # or truncate -s 0 $FILE # \"-s 0\" to specify the size # or cat /dev/null > $FILE # or dd if=/dev/null of=$FILE 传输文件 scp 对每个文件使用一个进程进行传输，而 rsync 只使用一个进程，因此一般 rsync 性能更高 rsync 只会传输修改的部分而不是整个文件，这使得 rsync 在需要更新或备份的情况下效率更高 # 将 source_folder 目录下的内容，copy 到 dest_folder 目录下 rsync -r source_folder/ dest_folder/ # 将 source_folder 目录，copy 到 dest_folder 目录下（以下若干种等价） rsync -r source_folder dest_folder/ rsync -r source_folder/ dest_folder/source_folder "},"docs/shell/shell-scripts.html":{"url":"docs/shell/shell-scripts.html","title":"Shell 脚本","keywords":"","body":"Shell Scripts Shell 脚本设置执行模式 set -x # 启用跟踪模式，即 shell 会在执行每个命令之前将该命令打印出来，然后再执行它 set -e # 设置错误退出模式，当任何命令返回非零退出状态码时，shell 将会立即终止执行，并退出脚本 set -u # 启用参数检查，如果尝试使用一个未定义的变量，shell 将会引发错误并终止脚本的执行 set -o pipefail # 当管道中的某个命令失败时，终止整个管道的执行 Bash 环境变量 HOME：用户的主目录 HOST：当前主机的名称 PWD：当前工作目录 RANDOM：返回一个 0 到 32767 之间的随机数 SHELL：Shell 的名字 UID：当前用户的 ID 编号 USER：当前用户的用户名 $?：上一个命令的退出码，用来判断上一个命令是否执行成功（返回值是 0，表示上一个命令执行成功；如果不是 0，表示上一个命令执行失败） $$：当前 Shell 的进程 ID，这个特殊变量可以用来命名临时文件，例如：LOGFILE=/tmp/output_log.$$ $!：最近一个后台执行的异步命令的进程 ID（用 & 执行的） $0：当前 Shell 的名称（在命令行直接执行时）或者脚本名（在脚本中执行时） $#：脚本的参数数量 $@：脚本的参数值 设置默认值 ${varname:-word}：如果 varname 存在且不为空，则返回它的值；否则，返回我们指定的默认值 word ${varname:=word}：如果 varname 存在且不为空，则返回它的值；否则，将 varname 设定为我们指定的默认值 word ${varname:+word}：如果 varname 存在且不为空，则返回我们指定的默认值 word；否则，返回空值 ${varname:?message}：如果 varname 存在且不为空，则返回它的值；否则，打印 message 并中断脚本执行（用于防止变量未定义） readonly foo=1 将 foo 设置为只读变量 Shell 整数运算、进制转换 echo $((2*3)) # 6 # echo $((N#xx)) 将其他进制转成十进制数 # N 为进制，xx 为该进制下某个数值，命令执行后可以得到该进制数转成十进制后的值 echo $((2#110)) # 6 echo $((16#2a)) # 42 使用 EOF 写入多行文本 NOTE: 若文本中包含 $ 则会直接执行，因此需要加上反斜杠进行转义，例如 \\$UserName 而不是 $UserName cat hello.txt foo bar EOF sudo tee -a hello.txt 用户输入 read 让用户输入 yes 再执行下一步： read -p \"Please type 'yes' to continue: \" input if [ \"$input\" != \"yes\" ]; then echo \"You did not enter 'yes'. Exit...\" exit 1 fi 让用户输入（但不关注内容）： echo \"请按回车键继续\" read -p \"\" mktemp 创建临时文件： #!/bin/bash TMPFILE=$(mktemp) || exit 1 # 确保临时文件创建成功 trap 'rm -rf $TMPFILE' EXIT # 保证脚本退出时临时文件被删除 echo \"Our temp file is $TMPFILE\" 创建临时文件夹： #!/bin/bash TMPDIR=$(mktemp -d) || exit 1 # 确保临时文件夹创建成功 trap 'rm -rf $TMPDIR' EXIT # 保证脚本退出时临时文件夹被删除 echo \"Our temp dir is $TMPDIR\" 终端文本颜色 参考 How to change the output color of echo in Linux RED='\\033[0;31m' YELLOW='\\033[1;33m' BLUE='\\033[0;34m' GREEN='\\033[0;32m' NC='\\033[0m' # No Color echo -e \"I ${RED}love${NC} Stack Overflow\" # printf \"I ${RED}love${NC} Stack Overflow\\n\" 参数解析 How do I parse command line arguments in Bash? #!/bin/bash function usage() { echo \"Usage: \" echo \" -e|--extension : File extension to search for\" echo \" -s|--searchpath : Path to search for files\" echo \" --default: Use default values\" } while [[ $# -gt 0 ]]; do case $1 in -e|--extension) EXTENSION=\"$2\" shift # past argument shift # past value ;; -s|--searchpath) SEARCHPATH=\"$2\" shift # past argument shift # past value ;; --default) DEFAULT=YES shift # past argument ;; *) echo \"Unknown option $1\" usage exit 1 ;; esac done echo \"FILE EXTENSION = ${EXTENSION}\" echo \"SEARCH PATH = ${SEARCHPATH}\" echo \"DEFAULT = ${DEFAULT}\" echo \"Number files in SEARCH PATH with EXTENSION:\" \"$(ls -1 \"${SEARCHPATH}\"/*.\"${EXTENSION}\" | wc -l)\" if [[ -n $1 ]]; then echo \"Last line of file specified as non-opt/last argument:\" tail -1 \"$1\" fi 前置检查：某工具是否存在 RED='\\033[0;31m' NC='\\033[0m' # No Color jq --version >& /dev/null || (echo -e \"${RED}jq${NC} not found\" && exit 1) ansible-playbook --version >& /dev/null || (echo -e \"${RED}ansible-playbook${NC} not found\" && exit 1) 查看文件是否存在 if [ ! -f /tmp/foo.txt ]; then echo \"file not found!\" exit 1 fi 要求 root 或 sudo 运行脚本 if [ `id -u` -ne 0 ] then echo Please run this script as root or using sudo! exit fi 实现 sudo 免密提权 UserName= echo \"$UserName ALL=(ALL) NOPASSWD:ALL\" | sudo tee -a /etc/sudoers > /dev/null 示例：创建用户（并创建同名用户组、配置密码、免密提权） #!/usr/bin/env bash set -xeuo pipefail # 需要以 root 运行，或者 sudo if [ `id -u` -ne 0 ] then echo Please run this script as root or using sudo! exit fi UserID=3001 UserName=hello UserPwd=world # -m 创建用户的 home 目录，默认为 /home/$UserName # -s SHELL 指定用户的 login shell # -u UID 指定用户的 User ID # -U 创建用户组，默认创建于 UserName 同名的用户组 useradd \\ -m \\ -s /bin/bash \\ -u $UserID \\ -U \\ $UserName id $UserName # 配置密码 echo \"$UserName:$UserPwd\" | chpasswd # 免密提权 echo \"$UserName ALL=(ALL) NOPASSWD:ALL\" | sudo tee -a /etc/sudoers > /dev/null "},"docs/shell/ssh.html":{"url":"docs/shell/ssh.html","title":"ssh","keywords":"","body":"ssh SSH 教程 - WangDoc ssh 执行脚本 ssh $UserName@$IP 'bash' 生成 ssh 密钥 默认会生成（1）公钥文件 ~/.ssh/id_rsa.pub（2）私钥文件 ~/.ssh/id_rsa ssh-keygen -t rsa -N \"\" -C \"user=$USER hostname=$HOSTNAME\" -f \"$HOME/.ssh/id_rsa\" 生成密钥以后，建议修改它们的权限，防止其他人读取： chmod 600 ~/.ssh/id_rsa chmod 600 ~/.ssh/id_rsa.pub ssh 连接远程服务器 UserName= && UserPwd= && IP= sshpass -p $UserPwd ssh $UserName@$IP 实现免密登录 - 将自己的 ssh 公钥 copy 到服务器上 将本机的 ~/.ssh/id_rsa.pub 公钥追加到远程服务器的 ~/.ssh/authorized_keys UserName= && UserPwd= && IP= sshpass -p $UserPwd ssh-copy-id $UserName@$IP 测试是否能 ssh 到服务器 ssh $UserName@$IP -o BatchMode=yes true &> /dev/null || echo \"fail\" ssh 连接流程 ssh 连接远程服务器后，首先有一个验证过程，验证远程服务器是否为陌生地址 如果是第一次连接某一台服务器，命令行会显示一段文字，表示不认识这台机器，提醒用户确认是否需要连接 The authenticity of host '192.168.0.110 (192.168.0.110)' can't be established. RSA key fingerprint is a3:ca:ad:95:a1:45:d2:57:3a:e9:e7:75:a8:4c:1f:9f. Are you sure you want to continue connecting (yes/no)? ssh 会将本机连接过的所有服务器公钥的指纹，都储存在本机的 ~/.ssh/known_hosts 文件中，每次连接服务器时，通过该文件判断是否为陌生主机（陌生公钥） 如果服务器的密钥发生变更（比如重装了 SSH 服务器、有人恶意冒充远程主机），客户端再次连接时，就会发生公钥指纹不吻合的情况，这时，客户端就会中断连接，并显示一段警告信息： @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ @ WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED! @ @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ IT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY! Someone could be eavesdropping on you right now (man-in-the-middle attack)! It is also possible that the RSA host key has just been changed. The fingerprint for the RSA key sent by the remote host is e9:0c:36:89:7f:3c:07:71:09:5a:9f:28:8c:44:e9:05. Please contact your system administrator. Add correct host key in /home/jiangxin/.ssh/known_hosts to get rid of this message. Offending key in /home/jiangxin/.ssh/known_hosts:81 RSA host key for 192.168.0.110 has changed and you have requested strict checking. Host key verification failed. 解决方案： 如果新的公钥确认可以信任，需要继续执行连接，你可以执行下面的命令，将原来的公钥指纹从 ~/.ssh/known_hosts 文件删除 HOSTNAME=发生公钥变更的主机名 ssh-keygen -R $HOSTNAME 临时解决方案： # ssh 加上参数 -o StrictHostKeyChecking=no sshd 查看当前生效的 ciphers sudo sshd -T | grep cipher 查看 /etc/ssh/sshd_config 配置的 cipher cat /etc/ssh/sshd_config | grep Ciphers "},"docs/shell/systemd.html":{"url":"docs/shell/systemd.html","title":"systemd","keywords":"","body":"systemd Systemd 入门教程：命令篇 —— 阮一峰的网络日志 systemctl list-units # 列出正在运行的 Unit systemctl list-units --all # 列出所有 Unit，包括没有找到配置文件的或者启动失败的 systemctl is-active nginx.service # 查看某个 Unit 是否正在运行，打印 active 并返回 0，或打印 inactive 并返回非零值 systemctl is-active nginx.service --quiet # 查看某个 Unit 是否正在运行，返回 0，或返回非零值 systemctl is-active nginx.service --quiet || systemctl restart nginx.service systemctl show httpd.service # 显示某个 Unit 的所有底层参数 systemctl show httpd.service -p CPUShares # 显示某个 Unit 的指定属性的值 systemctl cat nginx.service # 查看指定服务的配置文件的内容 systemctl edit nginx.service # 修改指定服务的配置文件的内容 sudo journalctl -u nginx.service # 查看某个 Unit 的日志 sudo journalctl -u nginx.service --since today hostnamectl # 查看当前主机的信息 localectl # 查看本地化设置 timedatectl # 查看当前时区设置 loginctl # 查看当前登录的用户 cron 查看已生效的 cron jobs crontab -l earlyoom earlyoom 每秒最多检查 10 次可用内存和可用交换空间（如果有大量可用内存，则频率会降低） 默认情况下，如果两者都低于 10%，它将杀死最大的进程（最高 oom_score），百分比值可通过命令行参数进行配置 注意：以 non-root 运行的 earlyoom 没法 kill 掉以 root 运行的进程 earlyoom 查看 log sudo journalctl -u earlyoom | grep -iE \"(sending|killing)\" earlyoom 配置文件 默认位置为 /etc/default/earlyoom，参数参考 Command Line Options，若修改了该文件，需要重启 earlyoom 服务： systemctl restart earlyoom "},"docs/shell/正则表达式.html":{"url":"docs/shell/正则表达式.html","title":"正则表达式","keywords":"","body":"正则表达式 regexp RegExr: Learn, Build, & Test RegEx regex101: build, test, and debug regex 基础正则 ^ 开头 $ 结尾 ^$ 空行 . 单个字符 * 前一个字符连续出现 0 次或 0 次以上 .* 任意内容 [abc] 匹配 a 或 b 或 c [^abc] 排除 a、排除 b、排除 c [0-9] 匹配单个数字 [a-z] 匹配单个小写字母 [A-Z] 匹配单个大写字母 [a-zA-Z] 匹配单个字母 [a-zA-Z0-9] 匹配单个字母或数字 [.! ]$ 匹配以 . 或 ! 或空格结尾的行（[] 会去掉符号的特殊含义） 扩展正则 ? 前一个字符出现 0 次或 1 次 + 前一个字符连续出现 1 次或 1 次以上 [a-zA-Z]+ 匹配单词 | 或匹配，例如 ubuntu|debian 匹配包含 ubuntu 或 debian 的行 () 表示一个 Group，用于反向引用 {n,m} 前一个字符至少出现 n 次、至多出现 m 次 {n} 前一个字符刚好出现 n 次 {n,} 前一个字符至少出现 n 次 {,m} 前一个字符至多出现 m 次 Perl 正则 \\d 匹配 [0-9] \\D 不匹配 [0-9]，即 [^0-9] \\s 匹配空字符、空格、tab、换行等 \\S 匹配非空字符 \\w 匹配 [0-9a-zA-Z_] \\W 不匹配 [0-9a-zA-Z_] "},"docs/shell/配置机器相关.html":{"url":"docs/shell/配置机器相关.html","title":"配置机器相关","keywords":"","body":"配置机器相关 查看 Linux 发行版 hostnamectl 查看 CPU 核数 lscpu | grep '^CPU(s)' | awk '{print $2}' 查看内存大小 cat /proc/meminfo | grep MemTotal | awk '{print $2}' # 16152104 即为 16G 查看硬盘空间 df --total -h | grep -e total -e Filesystem top id - Time spent in idle operations wa - Time spent on waiting on IO peripherals (eg. disk) 例如：若 MySQL 服务器上 top 的 wa 值较高，说明 I/O 压力比较大，排查慢查询等 查看机器重启的历史记录 last reboot -n 5 # Displays the last 5 system reboots last reboot -F # Displays the full date and time in the output 配置机器 sudo apt install build-essential -y Debian 配置 apt 镜像源 一般情况下，将 /etc/apt/sources.list 文件中 Debian 默认的源地址 http://deb.debian.org/ 替换为镜像地址即可 https://mirrors.tuna.tsinghua.edu.cn/help/debian/ sudo sed -i 's/^/#/' /etc/apt/sources.list sudo tee -a /etc/apt/sources.list Debian 12 配置 static IP 通过以下命令，找到一个网卡名称（例如 enp0s1，inet 192.168.64.3 ... dynamic ...） ip addr 然后，编辑 /etc/network/interfaces 文件： sudo vim /etc/network/interfaces 加入以下内容： auto enp0s1 # enp0s1 从 ip addr 查出来 iface enp0s1 inet static # enp0s1 从 ip addr 查出来 address 192.168.64.100 # 自己选的静态 IP netmask 255.255.255.0 gateway 192.168.64.1 dns-nameservers 8.8.8.8 # 一定要配这个，不要忽略 重启 networking 服务即可： sudo systemctl restart networking.server 再次 ip addr 查看是否配置生效 "},"docs/shell/vim.html":{"url":"docs/shell/vim.html","title":"Vim","keywords":"","body":"Vim 执行 Unix 命令 按下 Esc 返回命令模式，:!unix_command 即可 中文乱码 先查看文件的编码是否是 UTF-8： file xxx.txt 修改 ~/.vimrc，加上一下内容： set encoding=utf-8 "},"docs/shell/zsh.html":{"url":"docs/shell/zsh.html","title":"zsh","keywords":"","body":"zsh sudo apt install zsh -y # Debian brew install zsh # macOS Oh My Zsh # sh -c \"$(curl -fsSL https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh)\" sh -c \"$(curl -fsSL https://gitee.com/mirrors/oh-my-zsh/raw/master/tools/install.sh)\" # sh -c \"$(wget https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh -O -)\" # sh -c \"$(wget -O- https://gitee.com/pocmon/mirrors/raw/master/tools/install.sh)\" zsh-syntax-highlighting 语法高亮 zsh-syntax-highlighting/blob/master/INSTALL.md Debian sudo apt install zsh-syntax-highlighting -y echo \"source /usr/share/zsh-syntax-highlighting/zsh-syntax-highlighting.zsh\" >> ${ZDOTDIR:-$HOME}/.zshrc macOS brew install zsh-syntax-highlighting echo \"source $(brew --prefix)/share/zsh-syntax-highlighting/zsh-syntax-highlighting.zsh\" >> ${ZDOTDIR:-$HOME}/.zshrc zsh-autosuggestions 根据历史记录和完成情况进行提示 zsh-autosuggestions/blob/master/INSTALL.md git clone https://github.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestions 修改 ~/.zshrc 中启用的插件列表 plugins=( # other plugins... zsh-autosuggestions ) "},"docs/其他/其他.html":{"url":"docs/其他/其他.html","title":"其他","keywords":"","body":"其他 "},"docs/其他/其他-网络.html":{"url":"docs/其他/其他-网络.html","title":"网络","keywords":"","body":"其他-网络 Google HK 服务器无法访问 访问 www.google.com/ncr 即可 原理：Google 有一个基于国家和地区的自动重定向功能，默认情况我们访问时会被重定向到 .hk 服务器，但是发现 .hk 有时会没有响应，/ncr 可以强制不使用地区重定向，直接访问 Google 原服务器，这个操作在下一次清理浏览器 Cookie 之前都是生效的 Clash Linux 设置为 systemd /etc/systemd/system/clash.service "}}